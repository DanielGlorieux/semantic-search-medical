{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation du Moteur de Recherche\n",
    "Calcul de Recall@10, MRR@10 et autres métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append('../backend')\n",
    "from app.services.search_engine import SemanticSearchEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du moteur de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = SemanticSearchEngine()\n",
    "engine.load()\n",
    "print(\"✓ Moteur chargé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les queries de test (si disponibles)\n",
    "# queries_test = pd.read_csv('../data/processed/queries_test.csv')\n",
    "# qrels_test = pd.read_csv('../data/processed/qrels_test.csv')\n",
    "\n",
    "# Exemple de métriques\n",
    "metrics = {\n",
    "    'Recall@10': 0.0,\n",
    "    'MRR@10': 0.0,\n",
    "    'Latency (avg)': 0.0\n",
    "}\n",
    "\n",
    "print(\"Métriques d'évaluation:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Comment investir dans l'immobilier?\",\n",
    "    \"Quels sont les meilleurs placements financiers?\",\n",
    "    \"Comment calculer les impôts?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nRequête: {query}\")\n",
    "    results, latency = engine.search(query, top_k=3)\n",
    "    print(f\"Latence: {latency:.3f}s\")\n",
    "    for i, r in enumerate(results[:3]):\n",
    "        print(f\"  {i+1}. Score: {r['score']:.4f} - {r['text'][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
